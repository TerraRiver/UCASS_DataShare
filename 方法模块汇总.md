
1. 数据获取 (DA: Data Acquisition)

[ ] [DA01] 静态网页抓取 (Static Scraping): 使用 requests 和 BeautifulSoup4 抓取静态HTML页面并解析所需信息。

[ ] [DA02] 动态网页抓取 (Dynamic Scraping): 使用 Selenium 模拟浏览器操作（点击、滚动、登录），抓取JavaScript动态加载的内容。

[ ] [DA03] Scrapy框架入门 (Scrapy Framework): 介绍如何使用 Scrapy 构建一个结构化、可复用的爬虫项目，用于大规模抓取。

[ ] [DA04] API数据调用 (REST API Usage): 介绍如何使用 requests 库调用（如微博、知乎、高德地图）的JSON API，并处理返回数据。

[ ] [DA05] PRAW (Reddit API): 介绍如何使用 PRAW 包抓取Reddit论坛的帖子和评论数据。

[ ] [DA06] Tweepy (Twitter API): 介绍如何使用 Tweepy 包调用Twitter（X）的API。

[ ] [DA07] 数据库读取 (SQL Read): 使用 SQLAlchemy 或 psycopg2 从PostgreSQL/MySQL数据库中读取数据。

[ ] [DA08] MongoDB读取 (NoSQL Read): 使用 PyMongo 从MongoDB中查询和读取文档数据。

[ ] [DA09] PDF文本提取 (PDF Parsing): 使用 pdfplumber 或 PyMuPDF 批量从PDF文件中（如财报、政策文件）提取文本和表格。

[ ] [DA10] Word文档读取 (DOCX Parsing): 使用 python-docx 批量读取.docx文件内容。

[ ] [DA11] 图像OCR识别 (Image OCR): 使用 pytesseract 或 EasyOCR 识别图片中的文字。

2. 数据预处理与清洗 (DP: Data Preprocessing)

[ ] [DP01] Pandas基础操作 (Pandas Basics): DataFrame的创建、索引(loc/iloc)、切片和过滤。

[ ] [DP02] 缺失值处理 (Handling Missing Data): 介绍 dropna, fillna (均值、中位数、众数填充)等方法。

[ ] [DP03] 重复值处理 (Handling Duplicates): 介绍 drop_duplicates 的使用。

[ ] [DP04] 数据类型转换 (Type Conversion): 使用 astype 进行（如str转int, object转datetime）类型转换。

[ ] [DP05] 字符串处理 (String Manipulation): 使用 .str 访问器进行（contains, replace, split）操作。

[ ] [DP06] 正则表达式 (Regular Expressions): 使用 re 模块或 .str.extract 进行复杂文本的匹配和抽取（如抽取法律文书字段）。

[ ] [DP07] 数据合并 (Merging Data): 介绍 pd.merge 和 pd.join (left, right, inner, outer)。

[ ] [DP08] 数据拼接 (Concatenating Data): 介绍 pd.concat (axis=0, axis=1)。

[ ] [DP09] 数据重塑 (Reshaping Data): 介绍 pivot_table (数据透视表) 和 melt (宽表转长表)。

[ ] [DP10] 分组聚合 (Group & Aggregate): groupby 结合 agg, sum, mean, count 的使用。

[ ] [DP11] apply与lambda: 介绍如何使用 apply 和 lambda 函数进行自定义的行/列操作。

[ ] [DP12] 日期时间处理 (Time Series Basics): 使用 pd.to_datetime 解析时间，并按时间窗口（resample）进行聚合。

[ ] [DP13] 数据标准化 (Normalization): MinMaxScaler (归一化) 和 StandardScaler (Z-score标准化)。

[ ] [DP14] 类别变量编码 (Categorical Encoding): LabelEncoder (标签编码) 和 OneHotEncoder (独热编码)。

3. 基础定量与统计 (QS: Quantitative Statistics)

[ ] [QS01] 描述性统计 (Descriptive Statistics): pandas.describe()，计算均值、中位数、分位数、标准差等。

[ ] [QS02] 相关性分析 (Correlation Analysis): pandas.corr()，计算Pearson和Spearman相关系数。

[ ] [QS03] T检验 (T-test): scipy.stats.ttest_ind，用于比较两组均值是否有显著差异。

[ ] [QS04] 方差分析 (ANOVA): scipy.stats.f_oneway 或 statsmodels，用于比较多组均值差异。

[ ] [QS05] 卡方检验 (Chi-Square Test): scipy.stats.chi2_contingency，用于检验两个类别变量是否独立。

[ ] [QS06] OLS线性回归 (OLS Regression): statsmodels.api.OLS，执行多元线性回归并解读R方、p值、F统计量。

[ ] [QS07] Logit回归 (Logistic Regression): statsmodels.api.Logit，用于二元选择模型的分析。

[ ] [QS08] 回归诊断 (Regression Diagnostics): 检查多重共线性 (VIF) 和异方差。

[ ] [QS09] Bootstrap抽样 (Bootstrapping): 使用 sklearn.utils.resample 进行自助法抽样，估计置信区间。

4. 文本挖掘与NLP (NLP: Natural Language Processing)

[ ] [NLP01] 中文分词 (Chinese Segmentation): jieba (结巴分词)的基础用法（精确模式、全模式）和自定义词典加载。

[ ] [NLP02] PKUSEG分词 (PKUSEG): 介绍北大 pkuseg 工具包在特定领域（如法律、金融）的预训练模型。

[ ] [NLP03] 停用词处理 (Stopwords Removal): 加载和使用中文停用词表（如哈工大、百度停用词表）。

[ ] [NLP04] 词性标注 (POS Tagging): jieba.posseg，对词语进行词性（如n, v, adj）标注。

[ ] [NLP05] 命名实体识别 (NER): pkuseg 或 LTP (哈工大)，识别文本中的人名、地名、机构名。

[ ] [NLP06] 词袋模型 (Bag-of-Words): sklearn.feature_extraction.text.CountVectorizer 的使用。

[ ] [NLP07] TF-IDF (Term Frequency-IDF): sklearn.feature_extraction.text.TfidfVectorizer 的使用和解读。

[ ] [NLP08] N-Gram模型 (N-Grams): 在Vectorizers中设置 ngram_range (如bi-grams, tri-grams)。

[ ] [NLP09] 词典情感分析 (Dictionary Sentiment): 加载情感词典（如知网、大连理工），计算文本情感得分。

[ ] [NLP10] SnowNLP情感分析 (SnowNLP): 使用 snownlp 库对中文文本进行情感打分（0-1）。

[ ] [NLP11] 文本可读性 (Readability Scores): 计算中文文本的可读性指数（如字词、句法复杂度）。

[ ] [NLP12] LDA主题模型 (LDA Topic Modeling): gensim 或 sklearn 实现LDA，提取文本主题。

[ ] [NLP13] LDA参数调优 (LDA Tuning): 计算Perplexity和Coherence Score (C_v) 来选择最佳主题数K。

[ ] [NLP14] pyLDAvis可视化 (LDA Visualization): 使用 pyLDAvis 对LDA结果进行交互式可视化。

[ ] [NLP15] NMF主题模型 (Non-Negative Matrix): sklearn.decomposition.NMF，作为LDA的另一种替代。

[ ] [NLP16] BERTopic模型 (BERTopic): 基于BERT和HDBSCAN的现代主题模型，效果常优于LDA。

[ ] [NLP17] Word2Vec训练 (Training Word2Vec): gensim.models.Word2Vec，在自定义语料上训练词向量。

[ ] [NLP18] 预训练词向量 (Pre-trained Embeddings): 加载和使用大型预训练中文词向量（如腾讯、百度）。

[ ] [NLP19] 词向量相似度 (Word Similarity): model.wv.most_similar，计算词语相似度、类比（国王-男人+女人=王后）。

[ ] [NLP20] 语义变化分析 (Diachronic Analysis): 比较不同时期（如1980s vs 2010s）训练的词向量，分析概念（如“市场”）的语义变迁。

[ ] [NLP21] fastText (fastText): 介绍 fastText 模型，及其处理未登录词(OOV)的优势。

[ ] [NLP22] 文本相似度 (Text Similarity): sklearn.metrics.pairwise.cosine_similarity，计算文档间的余弦相似度。

[ ] [NLP23] 关键词提取 (Keyword Extraction): TextRank 或 TF-IDF 算法，从单篇文档中提取关键词。

[ ] [NLP24] 共现网络 (Co-occurrence Network): 构建词语共现矩阵，用于网络分析。

[ ] [NLP25] 文本摘要 (Text Summarization): gensim.summarization 或 sumy (Extractive)。

[ ] [NLP26] Transformers入门 (Hugging Face Intro): transformers 库的 pipeline 快速上手（情感分析、NER）。

[ ] [NLP27] BERT文本分类 (BERT Classification): 加载预训练BERT模型，并（在小数据集上）微调以进行文本分类（如新闻分类）。

[ ] [NLP28] BERT特征提取 (BERT as Feature): 提取BERT的[CLS]向量或词向量平均值，作为下游任务（如回归）的特征。

[ ] [NLP29] 零样本分类 (Zero-Shot Classification): transformers.pipeline("zero-shot-classification")，在没有训练数据的情况下对文本进行分类。

[ ] [NLP30] 依存句法分析 (Dependency Parsing): LTP 或 Stanza，分析句子成分（主谓宾）。

5. 网络分析 (SNA: Social Network Analysis)

[ ] [SNA01] NetworkX入门 (NetworkX Basics): NetworkX 库，创建图、添加/删除节点和边。

[ ] [SNA02] 图数据读写 (Graph I/O): 从边列表、邻接矩阵、GEXF/Pajek文件读写图。

[ ] [SNA03] 基础图可视化 (Basic Visualization): nx.draw，调整节点大小、颜色、标签。

[ ] [SNA04] 度中心性 (Degree Centrality): nx.degree_centrality，衡量节点的重要性。

[ ] [SNA05] 中介中心性 (Betweenness Centrality): nx.betweenness_centrality，衡量节点作为“桥梁”的能力。

[ ] [SNA06] 接近中心性 (Closeness Centrality): nx.closeness_centrality，衡量节点到其他节点的平均距离。

[ ] [SNA07] 特征向量中心性 (Eigenvector Centrality): nx.eigenvector_centrality，衡量节点邻居的重要性。

[ ] [SNA08] PageRank (PageRank): nx.pagerank，评估节点在网络中的“影响力”。

[ ] [SNA09] HITS (Hubs & Authorities): nx.hits，识别网络中的“枢纽”和“权威”。

[ ] [SNA10] 网络密度 (Density): nx.density，衡量网络的紧密程度。

[ ] [SNA11] 连通分量 (Connected Components): 识别网络中的“孤岛”和“子群”。

[ ] [SNA12] 社群发现 (Community Detection): python-louvain (Modularity)，识别网络中的“小团体”。

[ ] [SNA13] K核分析 (K-Core): nx.k_core，识别网络的核心-边缘结构。

[ ] [SNA14] 二部图 (Bipartite Graphs): 构建和分析“作者-论文”或“用户-商品”等二模网络。

[ ] [SNA15] PyVis交互可视化 (PyVis): pyvis 库，生成可交互的HTML网络图。

[ ] [SNA16] 结构洞 (Structural Holes): 计算网络的“约束系数”(Constraint)，识别占据结构洞的节点。

6. 空间分析与GIS (GIS: Geographic Information System)

[ ] [GIS01] GeoPandas入门 (GeoPandas Basics): GeoDataFrame 的创建和 shapely (Point, Line, Polygon)对象。

[ ] [GIS02] 空间数据读写 (Spatial I/O): geopandas.read_file，读取Shapefile和GeoJSON。

[ ] [GIS03] 坐标系转换 (CRS Transformation): to_crs，（如WGS84转Web Mercator）投影变换。

[ ] [GIS04] 空间连接 (Spatial Join): gpd.sjoin，（如“点在面内”）空间匹配。

[ ] [GIS05] 空间操作 (Spatial Operations): buffer (缓冲区), overlay (叠图分析), dissolve (融合)。

[ ] [GIS06] 地理编码 (Geocoding): geopy + 高德/百度API，实现“地址”到“经纬度”的转换。

[ ] [GIS07] 逆地理编码 (Reverse Geocoding): geopy，实现“经纬度”到“地址”的转换。

[ ] [GIS08] 静态地图可视化 (Static Mapping): geopandas.plot，绘制分层设色图 (Choropleth)。

[ ] [GIS09] 交互式地图 (Interactive Mapping): folium，在OpenStreetMap上绘制点、线、面和热力图。

[ ] [GIS10] 空间自相关 (Spatial Autocorrelation): pysal (libspatial), esda.Moran，计算全局和局部Moran's I。

[ ] [GIS11] 空间权重矩阵 (Spatial Weights): pysal (libspatial)，创建Queen/Rook邻接矩阵。

[ ] [GIS12] GWR (Geographically Weighted Regression): pysal (mgwr)，地理加权回归。

7. 机器学习 (ML: Machine Learning)

[ ] [ML01] 训练/测试集划分 (Train-Test Split): sklearn.model_selection.train_test_split。

[ ] [ML02] K折交叉验证 (K-Fold Cross-Validation): sklearn.model_selection.cross_val_score。

[ ] [ML03] 逻辑回归分类 (Logit Classification): sklearn.linear_model.LogisticRegression。

[ ] [ML04] 朴素贝叶斯 (Naive Bayes): sklearn.naive_bayes.MultinomialNB，常用于文本分类。

[ ] [ML05] K近邻 (KNN): sklearn.neighbors.KNeighborsClassifier。

[ ] [ML06] 决策树 (Decision Trees): sklearn.tree.DecisionTreeClassifier，及其可视化。

[ ] [ML07] 随机森林 (Random Forests): sklearn.ensemble.RandomForestClassifier/Regressor。

[ ] [ML08] SVM (Support Vector Machines): sklearn.svm.SVC，支持向量机分类。

[ ] [ML09] XGBoost (XGBoost): xgboost 库的使用（分类与回归）。

[ ] [ML10] LightGBM (LightGBM): lightgbm 库的使用。

[ ] [ML11] 分类评估指标 (Classification Metrics): 混淆矩阵、精确率(Precision)、召回率(Recall)、F1值。

[ ] [ML12] ROC与AUC (ROC & AUC): 绘制ROC曲线并计算AUC面积。

[ ] [ML13] 回归评估指标 (Regression Metrics): MSE (均方误差), R-squared (R方)。

[ ] [ML14] K-Means聚类 (K-Means Clustering): sklearn.cluster.KMeans。

[ ] [ML15] 肘方法 (Elbow Method): 确定K-Means的最佳K值。

[ ] [ML16] 层次聚类 (Hierarchical Clustering): scipy.cluster.hierarchy，绘制树状图。

[ ] [ML17] DBSCAN (DBSCAN): sklearn.cluster.DBSCAN，基于密度的聚类。

[ ] [ML18] PCA降维 (Principal Component Analysis): sklearn.decomposition.PCA。

[ ] [ML19] t-SNE可视化 (t-SNE Visualization): sklearn.manifold.TSNE，高维数据降维到2D/3D进行可视化。

[ ] [ML20] 网格搜索 (Grid Search CV): sklearn.model_selection.GridSearchCV，自动超参数调优。

[ ] [ML21] 特征重要性 (Feature Importance): 从随机森林或XGBoost中提取特征重要性排序。

8. 仿真与建模 (SM: Simulation & Modeling)

[ ] [SM01] Mesa (ABM)入门 (Mesa Intro): Mesa 库，构建基于主体建模(ABM)的基础框架。

[ ] [SM02] 谢林隔离模型 (Schelling's Segregation): 使用 Mesa 复现谢林隔离模型。

[ ] [SM03] 流行病模型 (SIR Model): 使用 Mesa 或 SciPy 模拟SIR（易感-感染-恢复）模型。

[ ] [SM04] 谣言传播模型 (Rumor Spreading): 模拟“遗忘-无知-传播”等状态的谣言传播模型。

[ ] [SM05] 系统动力学 (System Dynamics): PySD，运行Vensim/Stella构建的系统动力学模型。

9. 数据可视化 (DV: Data Visualization)

[ ] [DV01] Matplotlib (Matplotlib Basics): matplotlib.pyplot，绘制基础图表（线、柱、散点）。

[ ] [DV02] Seaborn (Seaborn Basics): seaborn，绘制统计图表（热力图、小提琴图、箱线图、分布图）。

[ ] [DV03] Seaborn多面板 (Seaborn FacetGrid): FacetGrid 和 PairGrid，绘制多子图。

[ ] [DV04] 词云 (Word Cloud): wordcloud 库，根据词频生成词云图。

[ ] [DV05] Plotly (Interactive Plotly): plotly.express，绘制可交互的HTML图表。

[ ] [DV06] Bokeh (Interactive Bokeh): bokeh，绘制可交互图表。

[ ] [DV07] Pyecharts (Pyecharts): pyecharts，生成符合百度Echarts标准的图表。

[ ] [DV08] Streamlit (Streamlit Dashboard): streamlit，快速构建交互式Web App/Dashboard。

[ ] [DV09] Dash (Dash Dashboard): Plotly Dash，构建更复杂的Web App。

10. 因果推断与高级方法 (CI: Causal Inference & Advanced)

[ ] [CI01] 倾向得分匹配 (PSM): causalinference 或 dowhy 库，实现Propensity Score Matching。

[ ] [CI02] 双重差分 (DiD): statsmodels，执行基础的Difference-in-Differences回归。

[ ] [CI03] 断点回归 (RDD): statsmodels，执行基础的Regression Discontinuity Design。

[ ] [CI04] 图像特征提取 (Image Features): Pillow 和 OpenCV，提取图片的基本特征（如颜色直方图）。

[ ] [CI05] 音频转录 (Audio Transcription): SpeechRecognition 或 whisper，将音频（如访谈录音）转为文本。
